# -*- coding: utf-8 -*-
"""asrs_nlp_pipeline_2001-2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aCwhvBGKGLEDyghTtr2xmd5c1peiJw8C
"""

!pip install gensim -qq numpy==1.26.4 gensim
get_ipython().kernel.do_shutdown(restart=True)

import pandas as pd
import glob

# Mount Google Drive if not already mounted
from google.colab import drive
drive.mount('/content/drive')

import os

# Paths to data directory
# data_paths = [
#     "/content/drive/MyDrive/Projects/Signature Project/Chris/Raw Data/raw_runway_incursion_data_Jan_2001_to_Dec_2017.csv",
#     "/content/drive/MyDrive/Projects/Signature Project/Chris/Raw Data/raw_runway_incursion_data_Jan_2018_to_May_2025.csv"
# ]
data_paths = [
    "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Raw Data/raw_runway_incursion_data_Jan_2001_to_Dec_2017.csv",
    "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Raw Data/raw_runway_incursion_data_Jan_2018_to_May_2025.csv"
]

df_list = []
for path in data_paths:
    try:
        df = pd.read_csv(path, skiprows=1, low_memory=False)  # Only skip first row (header text)
        df["source_file"] = path
        df_list.append(df)
    except Exception as e:
        print(f"Error reading {path}: {e}")

df_all = pd.concat(df_list, ignore_index=True)
print("Loaded", len(df_all), "rows.")
print("Columns:", df_all.columns.tolist())

# Exploratory Data Analysis
# Shape and basic info
print("Shape:", df_all.shape)
df_all.info()

# Quick look at nulls
df_all.isnull().mean().sort_values(ascending=False).head(20)

pd.set_option('display.max_columns', None)
print(df_all.head(5))

# Extract Contributing Factor Columns
contrib_cols = ["Contributing Factors / Situations", "Date"]
df_contrib = df_all[contrib_cols].copy()

# Convert 'Date' (in 'YYYYMM' format) to datetime
df_contrib["Date_parsed"] = pd.to_datetime(df_contrib["Date"], format="%Y%m", errors='coerce')

# Drop rows where conversion failed (malformed dates)
# df_contrib = df_contrib.dropna(subset=["Date_parsed"])

# Many ASRS reports list multiple contributing factors (Human Factors; Airspace Structure)
# So we split and explode multi-valued contributing factors
# This allows us to count or analyze individual contributing factors across all reports
df_exploded = df_contrib.assign(
    Factor=df_contrib["Contributing Factors / Situations"].str.split("; ")
).explode("Factor")

# Clean up empty or missing entries
df_exploded = df_exploded.dropna(subset=["Factor"])
df_exploded = df_exploded[df_exploded["Factor"].str.strip() != ""]

# Count and plot
factor_counts = df_exploded["Factor"].value_counts().reset_index()
factor_counts.columns = ["Factor", "Count"]

import matplotlib.pyplot as plt
import seaborn as sns
import textwrap

# Plot the bar chart
plt.figure(figsize=(12, 6))
sns.set_style("whitegrid")

# Wrapped labels
factor_counts["Factor_wrapped"] = factor_counts["Factor"].apply(
    lambda x: textwrap.fill(x, width=11)
)

barplot = sns.barplot(data=factor_counts, x="Factor_wrapped", y="Count", palette="tab10")

# Add count labels above each bar
for p in barplot.patches:
    height = p.get_height()
    barplot.annotate(
        f'{int(height)}',
        (p.get_x() + p.get_width() / 2, height),
        ha='center', va='bottom',
        fontsize=9,
        xytext=(0, 3),  # slight vertical offset
        textcoords="offset points"
    )

plt.title("Runway Incursion Contributing Factors (Jan 2001 – May 2025)", fontsize=16)
plt.xticks(rotation=0)  # Keep vertical since labels now wrap
plt.ylabel("Number of Reports")
plt.xlabel("Contributing Factor")
plt.tight_layout()
plt.show()

"""## Runway Incursion Contributing Factors (Jan 2001 – May 2025)

This chart shows the distribution of contributing factors across all runway incursion reports in the ASRS dataset spanning **January 2001 to May 2025**.

Each report may list one or more contributing factors as coded by ASRS analysts. The categories encompass human performance, airport infrastructure, procedural clarity, environmental disruptions, equipment issues, and organizational policies.

### Key Observations

- **Human Factors** overwhelmingly dominate, appearing in **5,119 reports**, underscoring their long-term centrality in runway incursion events and reflecting persistent challenges in decision-making, situational awareness, communication, and crew coordination.
- **Airport-Related Factors** are the second most common category with **2,151 reports**, pointing to ongoing issues with surface layout, signage, lighting, or construction zones.
- **Procedural Issues** appear in **1,006 reports**, signaling frequent difficulties in clearance instructions, readbacks, or procedural adherence.
- **Environmental – Non Weather Related** factors (e.g., lighting, visual obstructions, infrastructure) were cited in **702 reports**, ahead of **Aircraft Issues** (409) and **Chart or Publication Errors** (357).
- **Weather** contributed to **317 incidents**, with varying effects on visibility, handling, and surface conditions.
- Less common but notable factors include **Company Policy** (194), **ATC Equipment / Facility** (126), and **Airspace Structure** (114).
- Rare factors such as **Staffing** (46), **Incorrect/Unavailable Parts**, **Equipment/Tooling**, **Manuals**, and **Software/Automation** combined for fewer than 50 total reports—highlighting their minimal direct attribution as primary contributors.

### Interpretation

The distribution aligns closely with prior time-bound studies, reaffirming that **runway incursions are largely driven by human performance limitations** and systemic surface navigation complexity rather than isolated technical or environmental failures.

Key insights include:
- The **sheer volume of Human Factor reports** reinforces the need for resilient human-system interfaces, real-time support tools, and enhanced cognitive load mitigation strategies.
- The significant number of **Airport-related and Procedural issues** illustrates how physical layout and procedural ambiguity remain structural contributors to surface safety breakdowns.
- The prominence of **Environmental and Aircraft-related factors** also suggests the importance of considering infrastructure variability and mechanical readiness during surface ops.

### Conclusion

To improve runway safety over the long term, targeted interventions should emphasize:

- **Human-centered design** for procedures, communications, and interface systems  
- **Airport infrastructure modernization**, including better signage, markings, and lighting  
- **Standardized and simplified surface operation procedures**  
- **Continuous monitoring** of environmental and equipment-related variability using AI-driven analytics

This historical overview strengthens the case for sustained investment in **behavioral risk mitigation**, **surface navigation clarity**, and **data-informed policy adjustments** to reduce runway incursion risk across the national airspace system.
"""

# Ensure string values and filter only reports that include "Human Factors" in contributing factors
df_human_reports = df_all[df_all["Contributing Factors / Situations"].fillna("").str.contains("Human Factors")]

# Filter columns
df_hf = df_human_reports[["Human Factors", "Date"]].copy()

# Clean and explode subfactors
df_hf = df_hf.dropna(subset=["Human Factors"])
df_hf_exploded = df_hf.assign(Subfactor=df_hf["Human Factors"].str.split("; ")).explode("Subfactor")
df_hf_exploded = df_hf_exploded[df_hf_exploded["Subfactor"].str.strip() != ""]
df_hf_exploded["Subfactor"] = df_hf_exploded["Subfactor"].str.strip()

subfactor_counts = df_hf_exploded["Subfactor"].value_counts().reset_index()
subfactor_counts.columns = ["Subfactor", "Count"]

import matplotlib.pyplot as plt
import seaborn as sns
import textwrap

# Wrap labels
subfactor_counts["Label_wrapped"] = subfactor_counts["Subfactor"].apply(lambda x: textwrap.fill(x, width=11))

# Sort descending
subfactor_counts = subfactor_counts.sort_values("Count", ascending=False).reset_index(drop=True)

# Get reversed color palette (darkest = highest count)
num_bars = len(subfactor_counts)
colors = sns.color_palette("Blues", n_colors=num_bars)[::-1]  # reverse to make highest count darkest

# Plot
plt.figure(figsize=(12, 6))
sns.set_style("whitegrid")
barplot = sns.barplot(
    data=subfactor_counts,
    x="Label_wrapped",
    y="Count",
    palette=colors
)

# Annotate bar heights
for p in barplot.patches:
    height = p.get_height()
    barplot.annotate(f'{int(height)}',
                     (p.get_x() + p.get_width() / 2, height),
                     ha='center', va='bottom',
                     fontsize=9, xytext=(0, 3), textcoords="offset points")

plt.title("Distribution of Human Factor Subtypes (Jan 2001 – May 2025)", fontsize=16)
plt.xlabel("Human Factor Subtype")
plt.ylabel("Number of Reports")
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

"""## Distribution of Human Factor Subtypes (Jan 2001 – May 2025)

This chart presents a breakdown of **specific human factor subtypes** coded in ASRS reports that listed **Human Factors** as a contributing issue to runway incursions between **January 2001 and May 2025**.

Each report could be tagged with multiple subtypes, reflecting the multifaceted nature of human performance challenges in surface operations.

### Key Observations

- **Situational Awareness** is the leading human factor subtype, appearing in **1,272 reports**, indicating persistent issues with spatial misjudgment, attentional lapses, and mental model breakdowns during ground operations.
- **Communication Breakdown** is the second most prevalent category, with **1,056 mentions**, highlighting enduring problems in ATC-pilot exchanges including unclear instructions, frequency congestion, or misreadback.
- **Confusion** appears in **717 reports**, showing a strong association with ambiguous signage, misunderstood procedures, or expectation bias.
- **Distraction** is noted in **418 reports**, underscoring how multitasking, external stimuli, or operational noise impact crew focus and performance.
- Mid-frequency subtypes include:
  - **Workload** (**209**)
  - **Time Pressure** (**204**)
  - **Training / Qualification Gaps** (**197**)
  These collectively signal significant **cognitive strain and skill-based risks** during time-critical operations.
- Lower-frequency subtypes include:
  - **Other / Unknown** (**75**)
  - **Human-Machine Interface** (**63**)
  - **Troubleshooting** (**51**)
  - **Fatigue** (**45**)
  - **Physiological - Other** (**14**)  
  While infrequent, these categories may reflect underreporting or implicit challenges not always captured in structured coding.

### Interpretation

This long-term distribution reflects deeply embedded human-system interaction challenges in runway environments:

- The dominance of **Situational Awareness** and **Communication Breakdown** confirms that **perception**, **attention**, and **verbal clarity** are core risk areas across two decades.
- The consistent presence of **Confusion** and **Distraction** reveals how **visual and procedural ambiguity**, along with **attention management**, contribute to incursion risk.
- Emerging operational stressors are evident in the moderate counts for **Workload**, **Time Pressure**, and **Training**, suggesting an ongoing need for **crew preparedness**, **schedule realism**, and **real-time support tools**.
- Rare but meaningful subtypes like **Fatigue** and **Human-Machine Interface** may signal latent or under-recognized risks deserving more investigation.

### Conclusion

To reduce human-factor-related runway incursions over the long term, stakeholders should:

- Improve **ATC-pilot communication protocols** and enforce standard phraseology
- Enhance **situational awareness tools** and **surface navigation support**
- Incorporate **cognitive load management** and **scenario-based training** in crew programs
- Investigate and monitor less visible contributors such as **fatigue**, **interface design**, and **improvisational troubleshooting**

This expanded timespan reinforces that while technology evolves, core **cognitive and communication vulnerabilities** in surface operations persist—and must be addressed with both procedural and human-centered interventions.
"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sentence_transformers import SentenceTransformer, util
from tqdm.notebook import tqdm
tqdm.pandas()  # Enables .progress_apply()

# Ensure resources are downloaded
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('punkt_tab')

# Clean + normalize abbreviations
def basic_clean(text):
    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

import json

# Load full abbreviation mapping from file
with open("/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Misc/asrs_abbreviations.txt", "r") as f:
    lines = f.readlines()
# with open("/content/drive/MyDrive/Projects/Signature Project/Chris/Misc/asrs_abbreviations.txt", "r") as f:
#     lines = f.readlines()

# Build multi-definition dictionary
from collections import defaultdict

abbrev_multi_dict = defaultdict(list)
for line in lines:
    if ":" in line:
        key, val = line.strip().strip(',').replace('"', '').split(":", 1)
        key, val = key.strip(), val.strip()
        abbrev_multi_dict[key].append(val)

# abbrev_dict = {
#     "rwy": "runway",
#     "taxi": "taxiway",
#     "atc": "air traffic control",
#     "acft": "aircraft",
#     "flt": "flight",
#     "dep": "departure",
#     "arr": "arrival",
#     "ctlr": "controller",
#     "twr": "tower",
#     "fbo": "fixed base operator"
# }

# Initialize transformer model once
bert_model = SentenceTransformer("all-MiniLM-L6-v2")

import time

def disambiguate_abbreviation(context, abbr):
    definitions = abbrev_multi_dict.get(abbr.upper(), [])
    if not definitions:
        return abbr  # No mapping found

    start = time.time()
    context_embedding = bert_model.encode(context, convert_to_tensor=True)
    def_embeddings = bert_model.encode(definitions, convert_to_tensor=True)
    scores = util.cos_sim(context_embedding, def_embeddings)
    best_idx = scores.argmax().item()
    elapsed = time.time() - start

    if elapsed > 0.5:  # Only print slow cases
        print(f"[{abbr}] took {elapsed:.2f}s in context: {context[:50]}...")

    return definitions[best_idx].lower()


def normalize_abbr_contextual(text):
    words = text.split()
    new_words = []
    window = 5  # context size
    for i, word in enumerate(words):
        if word.upper() in abbrev_multi_dict:
            context = " ".join(words[max(i - window, 0):i + window + 1])
            full = disambiguate_abbreviation(context, word)
            new_words.append(full)
        else:
            new_words.append(word)
    return " ".join(new_words)

# Apply preprocessing with progress bar
df_all["Narrative"] = df_all["Narrative"].fillna("").astype(str)
df_all["narrative_clean"] = (
    df_all["Narrative"]
    .fillna("")
    .astype(str)
    .progress_apply(basic_clean)
    .progress_apply(normalize_abbr_contextual)
)

from gensim.models import Phrases
from gensim.models.phrases import Phraser

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def tokenize_lemmatize(text):
    tokens = nltk.word_tokenize(text)
    tokens = [
        lemmatizer.lemmatize(word)
        for word in tokens
        if word not in stop_words and word.isalpha() and len(word) > 2
    ]
    return tokens

df_all["narrative_tokens"] = df_all["narrative_clean"].apply(tokenize_lemmatize)

# Bigrams/trigrams
phrases = Phrases(df_all["narrative_tokens"], min_count=10, threshold=10)
bigram = Phraser(phrases)
df_all["narrative_ngrams"] = df_all["narrative_tokens"].apply(lambda tokens: bigram[tokens])

from collections import Counter

# Remove over-common tokens
all_tokens = [token for doc in df_all["narrative_ngrams"] for token in doc]
token_counts = Counter(all_tokens)
threshold = int(len(df_all) * 0.8)
common_terms = set([token for token, count in token_counts.items() if count > threshold])

df_all["narrative_final"] = df_all["narrative_ngrams"].apply(
    lambda tokens: [token for token in tokens if token not in common_terms]
)
df_all["narrative_final"] = df_all["narrative_final"].apply(
    lambda tokens: [t for t in tokens if not t.isdigit()]
)

# Save DataFrame with final tokenized narratives
preprocessed_path = "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Processed Data/preprocessed_for_topic_modeling_2001_to_2025_lda3.pkl"
# preprocessed_path = "/content/drive/MyDrive/Projects/Signature Project/Chris/Processed Data/preprocessed_for_topic_modeling_2001_to_2025_lda3.pkl"
df_all[["Date", "narrative_final"]].to_pickle(preprocessed_path)
print(f"Saved preprocessed narratives to: {preprocessed_path}")

import pandas as pd

preprocessed_path = "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Processed Data/preprocessed_for_topic_modeling_2001_to_2025_lda3.pkl"
# preprocessed_path = "/content/drive/MyDrive/Projects/Signature Project/Chris/Processed Data/preprocessed_for_topic_modeling_2001_to_2025_lda3.pkl"
df_preprocessed = pd.read_pickle(preprocessed_path)

print("Loaded shape:", df_preprocessed.shape)
print(df_preprocessed.head())

from gensim.models.ldamodel import LdaModel
from gensim import corpora

# Load the trained model and dictionary
lda_model_path = "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Models/lda_model_runway_incursions_3_2012_to_2017"
# lda_model_path = "/content/drive/MyDrive/Projects/Signature Project/Chris/Models/lda_model_runway_incursions_3_2012_to_2017"
lda_model = LdaModel.load(lda_model_path)

# dictionary_path = "/content/drive/MyDrive/Projects/Signature Project/Chris/Processed Data/dictionary_for_topic_modeling_2012_to_2017_lda3.pkl"
dictionary_path = "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Processed Data/dictionary_for_topic_modeling_2012_to_2017_lda3.pkl"
dictionary = corpora.Dictionary.load(dictionary_path)

# Process new (2018–2025) text into BoW format using the original dictionary
texts_new = df_preprocessed["narrative_final"].tolist()
corpus_new = [dictionary.doc2bow(text) for text in texts_new]

# Run inference
topics_new = [lda_model.get_document_topics(bow) for bow in corpus_new]

# View topic distributions
for i, topic_dist in enumerate(topics_new[:5]):
    print(f"Report {i+1}: {topic_dist}")

import numpy as np
topic_term_matrix = lda_model.get_topics()
row_sums = topic_term_matrix.sum(axis=1)
print("Min row sum:", np.min(row_sums))
print("Max row sum:", np.max(row_sums))

!pip install pyLDAvis

import pyLDAvis.gensim_models as gensimvis
import pyLDAvis

# Build pyLDAvis with normalized matrix
vis_data_new = gensimvis.prepare(
    topic_model=lda_model,
    corpus=corpus_new,
    dictionary=dictionary,
    sort_topics=False,
    mds='pcoa'
)

pyLDAvis.display(vis_data_new)

lda_vis_path = "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Visualizations/"
# lda_vis_path = "/content/drive/MyDrive/Projects/Signature Project/Chris/Visualizations/"
pyLDAvis.save_html(vis_data_new, lda_vis_path + 'lda_visualization_2001_to_2025.html')
pyLDAvis.save_json(vis_data_new, lda_vis_path + 'lda_visualization_2001_to_2025.json')

"""## LDA Topic Analysis of Runway Incursion Narratives (Jan 2001 – May 2025)

This visualization displays the results of a Latent Dirichlet Allocation (LDA) model applied to ASRS runway incursion reports from January 2001 to May 2025. The **Intertopic Distance Map** (left) shows the spatial relationships among five discovered topics, while the **Top-30 Most Salient Terms** (right) reveals the most informative keywords across the corpus.

### Topic Structure and Interpretation

The intertopic distance map reveals a moderate degree of semantic separation among the five topics:

- **Topic 3** is the most dominant (largest circle), suggesting it represents the most frequently occurring theme across the corpus.
- **Topic 4** and **Topic 2** are also substantial and moderately distinct.
- **Topic 1** is tightly clustered and relatively small, suggesting a narrow and specialized theme.

Based on the most salient terms, here are the likely interpretations of each topic:

#### **Topic 1 – Frequency Management and Coordination Signals**
Top keywords: `frequency`, `advisory_frequency`, `notice_airman`, `air_mission`, `controller_charge`

- Focuses on **communication infrastructure** issues (e.g., NOTAMs, frequency assignment, radio confusion)
- Likely corresponds to incidents involving **technical coordination issues or regulatory messaging**

#### **Topic 2 – Procedural Confusion and Surface Navigation**
Top keywords: `instruction`, `rule`, `issued`, `local`, `instructed`, `local_controller`

- Emphasizes **instruction timing**, **controller interactions**, and **clearance confusion**
- Aligns with procedural ambiguity or mixed ATC instructions leading to runway incursions

#### **Topic 3 – ATC-Pilot Communication and Situational Awareness**
Top keywords: `vehicle`, `crossing`, `cross`, `position`, `closed`, `ground_control`, `operation`, `around`, `pilot`, `traffic`

- Captures the **core interactions between pilots and ATC** during ground movement
- Encompasses **clearance violations**, **traffic awareness**, and **runway/taxiway coordination**

#### **Topic 4 – Departure/Arrival Flow and Misjudgment**
Top keywords: `departure`, `south`, `pilot`, `operation`, `aircraft_zulu`

- Related to **departures and arrival phases**, possibly including **runway alignment**, **routing**, and **ATC sequencing**
- Likely linked to **runway confusion or early/late takeoff and landing issues**

#### **Topic 5 – Positional Awareness and Traffic Conflict**
Top keywords: `position`, `around`, `clear`, `traffic`, `close`, `notice`

- Involves **crew awareness**, **runway environment scanning**, and **movement timing**
- May include **situational breakdowns**, such as **holding short violations or missed vehicle spotting**

---

### Topic Distribution Across Sample Reports

The LDA topic proportions for 5 sampled reports highlight how incidents often involve a **blend of overlapping themes**:

| Report | Dominant Topics                    | Interpretation                                                                 |
|--------|------------------------------------|---------------------------------------------------------------------------------|
| 1      | Topic 3 (55%), Topic 4 (43%)       | Ground coordination mixed with departure/takeoff phase confusion               |
| 2      | Topic 2 (73%), Topic 1 (26%)       | Strong procedural confusion with secondary frequency management issues         |
| 3      | Topic 3 (61%), Topic 4 (15%), others minor | ATC-pilot ground communication dominates, with light procedural ambiguity     |
| 4      | Topic 2 (61%), Topic 3 (24%), Topic 1 (13%) | Procedural confusion dominates, backed by ground coordination                 |
| 5      | Topic 3 (60%), Topic 4 (39%)       | Heavy ground movement issues and runway sequencing challenges                  |

These distributions reinforce the LDA model’s **utility in capturing layered risk dimensions** within each narrative.

---

### Interpretation

- **Topics 2 and 3** are the most prevalent, aligning with long-known risk categories: **procedural misunderstanding** and **surface coordination failure**.
- **Topic 4’s frequent pairing with Topic 3** suggests many incursions stem from **departure/taxi phase transitions**, where both instruction clarity and situational awareness are critical.
- **Topic 1’s presence in fewer but clear cases** reflects **infrastructure or regulatory signal confusion**, which may not occur often but can have cascading effects.

---

### Conclusion

This LDA model effectively reveals **thematic clusters** in over two decades of runway incursion narratives:

- Core risks stem from **communication breakdowns**, **misunderstood instructions**, and **surface miscoordination**.
- **Semantic clustering** provides valuable input for tagging and monitoring evolving safety trends.
- Integrating these insights with contributing factor codes and NLP outputs can strengthen runway incursion prevention efforts.

Future work may include:
- Time-based drift analysis of topic prominence
- Alignment with human factor subtypes and coded contributing factors
- Use in similarity search, tagging, or summarization pipelines
"""

!pip install bertopic sentence-transformers umap-learn -q

# BERTopic is less reliant on tokenization and lemmatization than LDA because it
# leverages pre-trained transformer models like BERT for generating sentence
# embeddings, which capture semantic meaning more effectively
preprocessed_path = "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Processed Data/preprocessed_for_topic_modeling_2001_to_2025_lda3.pkl"
df_preprocessed = pd.read_pickle(preprocessed_path)
docs = [" ".join(tokens) for tokens in df_preprocessed["narrative_final"] if len(tokens) >= 15]

from sentence_transformers import SentenceTransformer

# Use the same model as the previous research study
embedding_model = SentenceTransformer("all-mpnet-base-v2")

from bertopic import BERTopic

# Load the trained model
topic_model = BERTopic.load("/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Models/BERTopic_model_runway_incursions_3")
# topic_model = BERTopic.load("/content/drive/MyDrive/Projects/Signature Project/Chris/Models/BERTopic_model_runway_incursions_3")

# Prepare new (2018–2025) docs as plain strings
docs_new = [" ".join(tokens) for tokens in df_preprocessed["narrative_final"] if len(tokens) >= 15]

# Apply model to new data
topics_new, probs_new = topic_model.transform(docs_new)

# View top words in each reused topic
topic_info = topic_model.get_topic_info()
for topic_num in topic_info["Topic"].tolist():
    if topic_num == -1:  # -1 is typically "Outliers"
        continue
    print(f"\nTopic {topic_num}:")
    print(topic_model.get_topic(topic_num))
topic_model.get_topic_info()

topic_model.visualize_topics()

bertopic_vis_path = "/content/drive/MyDrive/Schoolwork/Spring 2025/ITP 459/Signature Project/Chris/Visualizations/"
topic_model.visualize_topics().write_html(bertopic_vis_path + 'bertopic_visualization_6_topic_2001_to_2025.html')

"""# BERTopic Analysis: Runway Incursion Narratives (2001–2025)

This analysis summarizes six dominant topics extracted using the BERTopic model from ASRS runway incursion narratives spanning January 2001 to May 2025. The **Intertopic Distance Map** and top-ranked keywords are used to interpret thematic clusters and their operational significance.

---

## Intertopic Distance Map Interpretation

The intertopic distance map reveals moderate semantic separation:

- **Topics 0, 1, and 2** form the central cluster, suggesting overlapping concerns related to communication protocols and airspace rules.
- **Topics 3, 4, and 5** are more spatially dispersed, indicating more distinct and specialized contexts (e.g., snow hazards, surface signage confusion).

This distribution suggests that while foundational issues like clearances and airspace regulation dominate the dataset, smaller clusters capture context-specific safety threats that should not be overlooked.

---

## Topic-by-Topic Analysis

### **Topic 0 – Notices, Regulations, and Airspace Rules**
**Top Terms**: `notice_airman air_mission`, `air_traffic control`, `visual_flight rule`, `automatic_terminal information_service`, `federal_aviation regulation`

- **Interpretation**: Represents **pre-flight awareness**, **NOTAMs**, and VFR/IFR regulatory transitions.
- **Significance**: Highlights how procedural awareness and airspace control structure remain a vital component of runway safety.
- **Volume**: 213 documents.

---

### **Topic 1 – Surface Clearance and Readback Violations**
**Top Terms**: `cleared cross`, `crossed_hold short_line`, `short final`, `read_back`, `told stop`, `cleared takeoff`

- **Interpretation**: Reflects **LUAW violations**, **runway crossing confusion**, and **readback/hearback failures**.
- **Significance**: Most semantically rich and operationally common cluster; echoes known vulnerabilities in ATC-pilot communication.
- **Volume**: 180 documents.

---

### **Topic 2 – IFR Traffic, Frequencies, and Flight Plans**
**Top Terms**: `instrument_flight rule`, `common_traffic advisory_frequency`, `final approach`, `flight_plan`, `federal_aviation regulation`

- **Interpretation**: Focuses on **controlled airspace ops**, **instrument procedures**, and **radio coordination**.
- **Significance**: Often tied to **transition between towered/non-towered fields**, where frequency confusion or plan deviations arise.
- **Volume**: 145 documents.

---

### **Topic 3 – Aborted Takeoffs and Ground Vehicle Conflicts**
**Top Terms**: `cleared takeoff`, `crossed_hold short_line`, `ground vehicle`, `cancelled takeoff_clearance`, `climb foot`, `operation vehicle`

- **Interpretation**: Captures **takeoff clearances rescinded due to vehicle intrusions or last-minute conflict recognition**.
- **Significance**: Represents **high-consequence, time-sensitive coordination failures** at the runway threshold.
- **Volume**: 35 documents.

---

### **Topic 4 – Snow, Ice, and Surface Friction Hazards**
**Top Terms**: `snow removal`, `snow plow`, `maximum brake`, `intersection kilo`, `black ice`

- **Interpretation**: Seasonal incidents involving **snow operations, reduced braking, and icy taxiway/runway surface events**.
- **Significance**: Though infrequent, the risk severity is high, warranting seasonal runway condition monitoring and deicing protocols.
- **Volume**: 11 documents.

---

### **Topic 5 – Non-Movement Areas and Signage Confusion**
**Top Terms**: `non movement_area`, `heading reference`, `taxi_via concrete`, `mach_number sign`, `irregular operation`, `join zulu`

- **Interpretation**: Concerns **non-standard instructions**, **non-movement areas**, and **ambiguous signs or markings**.
- **Significance**: Suggests lack of clarity in low-visibility or uncontrolled segments of airport surfaces.
- **Volume**: 10 documents.

---

## Summary Table

| Topic | Theme                                      | Volume | Risk Type              |
|-------|--------------------------------------------|--------|------------------------|
| 0     | Airspace Regulations & Advisory Notices    | 213    | Procedural Awareness   |
| 1     | Clearance Readbacks & Crossing Violations  | 180    | Communication Error    |
| 2     | IFR Rules & Frequency Coordination         | 145    | Radio/Plan Confusion   |
| 3     | Vehicle Conflict & Takeoff Abortions       | 35     | Emergency Response     |
| 4     | Snow/Ice Surface Hazards                   | 11     | Seasonal/Environmental |
| 5     | Non-Movement Area & Signage Confusion      | 10     | Infrastructure Clarity |

---

## Key Takeaways

- **Topic 1** remains the most operationally concerning cluster, tied directly to **clearance and communication breakdowns**.
- **Topic 3 and 4**, while low in frequency, involve **high-severity scenarios** (e.g., aborted takeoffs, icy runways) and require proactive mitigation.
- **Topic 5** introduces a subtle but persistent risk: **unclear surface instructions in marginal or non-towered zones**.

---

## Recommendations

1. **Strengthen controller-pilot communication protocols**, especially for hold short and readback loops (Topic 1).
2. **Clarify advisory frequency transitions and reinforce IFR/VFR awareness** through enhanced training (Topic 2).
3. **Deploy snow/ice sensors and integrate braking action reports** into real-time dashboards (Topic 4).
4. **Audit non-movement area signage and revise confusing taxi instructions** (Topic 5).

BERTopic’s results show that while dominant themes persist over time, **thematic granularity** enables **targeted policy improvements**, particularly in edge-case scenarios where documentation or physical layout may lag safety standards.
"""